{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch Basics.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRRCgkWV0ljE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIa0Y5ej2Qlq",
        "colab_type": "text"
      },
      "source": [
        "## 1. Basic autograd example I"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEMOH3hJ2M8T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a461c61d-1c08-4a92-dca3-49691f8dffa6"
      },
      "source": [
        "## Creating tensors\n",
        "\n",
        "x = torch.tensor(1., requires_grad = True)\n",
        "w = torch.tensor(2., requires_grad = True)\n",
        "b = torch.tensor(3., requires_grad = True)\n",
        "\n",
        "## Building a computational graph\n",
        "\n",
        "y = w * x + b   ## y = 2 * x + 3\n",
        "\n",
        "## Computing gradients\n",
        "\n",
        "y.backward()\n",
        "\n",
        "## Printing out the gradients\n",
        "\n",
        "print(x.grad)    ## x.grad = 2\n",
        "print(w.grad)    ## w.grad = 1\n",
        "print(b.grad)    ## b.grad = 1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.)\n",
            "tensor(1.)\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D0H9GU75Kxc",
        "colab_type": "text"
      },
      "source": [
        "## 2. Basic autograd example II"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELiLq2_A38Mt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "669056ce-9fa0-4acf-98cd-fe9e59364448"
      },
      "source": [
        "## Creating tensors of shape (10, 3) and (10, 2)\n",
        "\n",
        "x = torch.randn(10, 3)\n",
        "y = torch.randn(10, 2)\n",
        "\n",
        "## Building a fully connected layer\n",
        "\n",
        "linear = nn.Linear(3, 2)\n",
        "print('w: ', linear.weight)\n",
        "print('b: ', linear.bias)\n",
        "\n",
        "## Building loss function and optimizer\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr = 0.01)\n",
        "\n",
        "## Forward pass\n",
        "\n",
        "pred = linear(x)\n",
        "\n",
        "## Computing loss\n",
        "\n",
        "loss = criterion(pred, y)\n",
        "print('loss: ', loss.item())\n",
        "\n",
        "## Backward pass\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "## Printing out the gradients\n",
        "\n",
        "print('dL/dw: ', linear.weight.grad)\n",
        "print('dL/db: ', linear.bias.grad)\n",
        "\n",
        "## 1-step gradient descent\n",
        "\n",
        "optimizer.step()\n",
        "\n",
        "## We can also perform gradient descent at the low level\n",
        "## linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n",
        "## linear.bias.data.sub_(0.01 * linear.bias.grad.data)\n",
        "\n",
        "## Printing out the loss after 1-step gradient descent\n",
        "\n",
        "pred = linear(x)\n",
        "loss = criterion(pred, y)\n",
        "print('Loss after 1 step optimization: ', loss.item())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w:  Parameter containing:\n",
            "tensor([[ 0.0454, -0.0579,  0.3991],\n",
            "        [-0.0934,  0.0433, -0.5403]], requires_grad=True)\n",
            "b:  Parameter containing:\n",
            "tensor([-0.1898, -0.4294], requires_grad=True)\n",
            "loss:  2.3460278511047363\n",
            "dL/dw:  tensor([[ 0.5725, -0.2721,  0.9797],\n",
            "        [-0.0703,  0.1186, -0.7376]])\n",
            "dL/db:  tensor([ 0.0239, -0.0105])\n",
            "Loss after 1 step optimization:  2.326878070831299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XL10UjIv75cq",
        "colab_type": "text"
      },
      "source": [
        "## 3. Loading data from numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ptE32Ny7hnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Creating a numpy array\n",
        "\n",
        "x = np.array([[5, 6], [7, 8]])\n",
        "\n",
        "## Converting the numpy array to a torch tensor\n",
        "\n",
        "y = torch.from_numpy(x)\n",
        "\n",
        "## Convert the torch tensor to a numpy array\n",
        "\n",
        "z = y.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwYyet2J9jPu",
        "colab_type": "text"
      },
      "source": [
        "## 4. Input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VjcyVSy9ho5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "39599da0-7b6e-455b-a67a-c84735ab0d8e"
      },
      "source": [
        "## Download and construct CIFAR-10 dataset\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root = '../../data/',\n",
        "                                             train = True,\n",
        "                                             transform = transforms.ToTensor(),\n",
        "                                             download = True)\n",
        "\n",
        "## Fetch one data pair (read data from disk)\n",
        "\n",
        "image, label = train_dataset[0]\n",
        "print(image.size())\n",
        "print(label)\n",
        "\n",
        "## Data loader (this provides queues and threads in a very simple way)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = 64,\n",
        "                                           shuffle = True)\n",
        "\n",
        "## When iteration starts, queue and thread start to load data from files\n",
        "\n",
        "data_iter = iter(train_loader)\n",
        "\n",
        "## Mini-batch images and labels\n",
        "\n",
        "images, labels = data_iter.next()\n",
        "\n",
        "## Actual usage of the data loader is as below\n",
        "\n",
        "for images, labels in train_loader:\n",
        "  ## Training code should be written here\n",
        "  pass"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../../data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170500096it [00:06, 26911099.52it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 32, 32])\n",
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH2ltBTw_mIR",
        "colab_type": "text"
      },
      "source": [
        "## 5. Input pipeline for custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAl065Za_d6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## You should build your custom dataset as below\n",
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self):\n",
        "    ## TODO\n",
        "    ## 1. Initialize file paths or a list of file names\n",
        "    pass\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    ## TODO\n",
        "    ## 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open)\n",
        "    ## 2. Preprocess the data (e.g. torchvision.Transform)\n",
        "    ## 3. Return a data pair (e.g. image and label)\n",
        "    pass\n",
        "  \n",
        "  def __len__(self):\n",
        "    ## You should change 0 to the total size of your dataset\n",
        "    return 0\n",
        "  \n",
        "## You can then use the prebuilt data loader\n",
        "\n",
        "custom_dataset = CustomDataset()\n",
        "train_loader = torch.utils.data.DataLoader(dataset = custom_dataset,\n",
        "                                           batch_size = 64,\n",
        "                                           shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whoOEvXgA_GU",
        "colab_type": "text"
      },
      "source": [
        "## 6. Pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaJNbjTEAzb8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "ffb33706-bd5d-4253-c58c-b07e35a120f9"
      },
      "source": [
        "## Download and load the pretrained ResNet-18\n",
        "\n",
        "resnet = torchvision.models.resnet18(pretrained = True)\n",
        "\n",
        "## If you want to finetune only the top layer of the model, set as below\n",
        "\n",
        "for param in resnet.parameters():\n",
        "  param.requires_grad = False\n",
        "  \n",
        "## Replace the top layer for finetuning\n",
        "\n",
        "resnet.fc = nn.Linear(resnet.fc.in_features, 100)    ## 100 is an example\n",
        "\n",
        "## Forward pass\n",
        "\n",
        "images = torch.randn(64, 3, 224, 224)\n",
        "outputs = resnet(images)\n",
        "print(outputs.size())    ## (64, 100)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n",
            "100%|██████████| 46827520/46827520 [00:01<00:00, 30907690.64it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWXp7IMTDSO8",
        "colab_type": "text"
      },
      "source": [
        "## 7. Save and load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSNwQj-mC1-l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b6b1c10d-7912-4c7a-dde3-d6bcd7879a9b"
      },
      "source": [
        "## Save and load the entire model\n",
        "\n",
        "torch.save(resnet, 'model.ckpt')\n",
        "model = torch.load('model.ckpt')\n",
        "\n",
        "## Save and load only the model parameters (recommended)\n",
        "\n",
        "torch.save(resnet.state_dict(), 'params.ckpt')\n",
        "resnet.load_state_dict(torch.load('params.ckpt'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}